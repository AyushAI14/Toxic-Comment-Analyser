# ğŸ§  Toxic Comment Analyzer

Analyze YouTube video comments and detect toxicity using a fine-tuned DistilBERT model, all wrapped in a FastAPI backend and a minimal frontend UI.

![Result Screenshot](./aaf6a21d-1dae-4cca-9d37-052d6f8d25bf.png)

---

## ğŸš€ Features

- ğŸ” Scrapes YouTube comments using a given video URL
- âœ¨ Cleans and processes text using custom pipelines
- ğŸ¤– Predicts toxicity using `martin-ha/toxic-comment-model` (DistilBERT)
- ğŸ“Š Shows percentage of toxic/non-toxic comments + average confidence
- ğŸ–¥ï¸ Simple frontend with HTML+CSS and a loading spinner
- ğŸ“ MLOps-structured project with modular components
- ğŸ³ Docker-ready

---

## ğŸ›  Tech Stack

- FastAPI
- HuggingFace Transformers (`distilbert-toxic-model`)
- PyTorch
- HTML + CSS
- Jinja2 (for rendering)
- Logging & YAML Configs
- Docker

---

## ğŸ“‚ Project Structure

```bash
.
â”œâ”€â”€ app.py                          # FastAPI entrypoint
â”œâ”€â”€ templates/index.html           # Frontend template
â”œâ”€â”€ src/                           # ML pipeline modules
â”œâ”€â”€ artifacts/                     # Stored artifacts
â”œâ”€â”€ distilbert-toxic-model-v1/     # Pretrained model files
â”œâ”€â”€ notebook/                      # EDA, training notebooks
â”œâ”€â”€ Dockerfile                     # For containerization
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ config/config.yaml             # Configuration
â”œâ”€â”€ main.py                        # Alternate CLI entrypoint
â””â”€â”€ README.md                      # This file
