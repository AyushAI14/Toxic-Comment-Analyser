# ğŸ§  Toxic Comment Analyzer

Analyze YouTube video comments and detect toxicity using a fine-tuned DistilBERT model, all wrapped in a FastAPI backend and a minimal frontend UI.

![Image](https://github.com/user-attachments/assets/f986cbdb-b0e3-44a3-a0f9-c17938194cfd)
---

## ğŸš€ Features

- ğŸ” Scrapes YouTube comments using a given video URL
- âœ¨ Cleans and processes text using custom pipelines
- ğŸ¤– Predicts toxicity using `martin-ha/toxic-comment-model` (DistilBERT)
- ğŸ“Š Shows percentage of toxic/non-toxic comments + average confidence
- ğŸ–¥ï¸ Simple frontend with HTML+CSS and a loading spinner
- ğŸ“ MLOps-structured project with modular components
- ğŸ³ Dockerization

---

## ğŸ›  Tech Stack

- Python
- FastAPI
- HuggingFace Transformers (`distilbert-toxic-model`)
- PyTorch
- HTML + CSS
- Jinja2 (for rendering)
- Logging & YAML Configs
- Docker
- Deployment app in EC2
- CI/CD Integration
---

## ğŸ“‚ Project Structure

```bash
.
â”œâ”€â”€ app.py                          # FastAPI entrypoint
â”œâ”€â”€ templates/index.html           # Frontend template
â”œâ”€â”€ src/                           # ML pipeline modules
â”œâ”€â”€ artifacts/                     # Stored artifacts
â”œâ”€â”€ notebook/                      # EDA, training notebooks
â”œâ”€â”€ Dockerfile                     # For containerization
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ config/config.yaml             # Configuration
â”œâ”€â”€ main.py                        # Alternate CLI entrypoint
â””â”€â”€ README.md                      # This file

```

